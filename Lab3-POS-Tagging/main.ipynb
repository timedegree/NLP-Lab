{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from random import choice\n",
    "import jieba.posseg as pseg\n",
    "import jieba\n",
    "import snownlp\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_list(path):\n",
    "    file_list = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files[:20000]:\n",
    "            if file.endswith('.txt'):\n",
    "                file_list.append(os.path.join(root, file))\n",
    "    return file_list\n",
    "\n",
    "def read_file(file_list):\n",
    "    content = []\n",
    "    for file in file_list:\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            content.append(f.read())\n",
    "    return content\n",
    "\n",
    "def read_stopwords():\n",
    "    stopwords = []\n",
    "    with open('../source/cn_stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            stopwords.append(line.strip())\n",
    "    return stopwords\n",
    "\n",
    "file_list = get_file_list('../source/politics')\n",
    "content = read_file(file_list)\n",
    "stopwords = read_stopwords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count = Counter()\n",
    "words_count_stopwords = Counter()\n",
    "\n",
    "symbol_pattern = re.compile(\n",
    "    r'[^\\w\\u4e00-\\u9fa5]'\n",
    ")\n",
    "\n",
    "for text in content:\n",
    "    words = [word for word in jieba.lcut(re.sub(r'[\\d\\.-]+', '', text))]\n",
    "    words = [word for word in words if not symbol_pattern.match(word)]\n",
    "    words_count.update(words)\n",
    "    \n",
    "    words = [word for word in words if word not in stopwords and len(word) > 1]\n",
    "    words_count_stopwords.update(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('most_common_words_with_stopwords:')\n",
    "for word, count in words_count.most_common(10):\n",
    "    print(f'{word}: {count}')\n",
    "\n",
    "print('most_common_words_without_stopwords:')\n",
    "for word, count in words_count_stopwords.most_common(10):\n",
    "    print(f'{word}: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = choice(content)\n",
    "\n",
    "words = pseg.cut(text)\n",
    "words = [(word, flag) for word, flag in words if not symbol_pattern.match(word)]\n",
    "for word, flag in words:\n",
    "    print(f'{word} {flag}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = snownlp.SnowNLP(text)\n",
    "words = [(word, flag) for word, flag in words.tags if not symbol_pattern.match(word)]\n",
    "\n",
    "for word, flag in words:\n",
    "    print(f'{word} {flag}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
