{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "from nltk.corpus import sinica_treebank\n",
    "import jieba\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process\n",
    "with open('../source/cn_stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = f.read().splitlines()\n",
    "\n",
    "s = \"此外，公司拟对全资子公司吉林欧亚置业有限公司增资4.3亿元，增资后，吉林欧亚置业注册资本由7000万元增加到5亿元。吉林欧亚置业主要经营范围为房地产开发及百货零售等业务。目前在建吉林欧亚城市商业综合体项目。2013年，实现营业收入0万元，实现净利润-139.13万元。\"\n",
    "\n",
    "words = [word for word in jieba.lcut(re.sub(r'[\\d\\.-]+', '', s)) if len(word) > 1 and not word in stopwords ]\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyword Extraction using gensim LSA\n",
    "\n",
    "dictionary = corpora.Dictionary([words])\n",
    "corpus = [dictionary.doc2bow(words)]\n",
    "lsa = models.LsiModel(corpus, id2word=dictionary, num_topics=1)\n",
    "\n",
    "for topic_id, topic in lsa.print_topics(num_words=5):\n",
    "    keywords = [word.rstrip('\"').split(r'*\"') for word in topic.split(\" + \")]\n",
    "\n",
    "weight = [float(word[0]) for word in keywords]\n",
    "keywords = [word[1] for word in keywords]\n",
    "\n",
    "for i in range(len(keywords)):\n",
    "    print(f\"{keywords[i]} {weight[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyword Extraction using gensim LDA\n",
    "\n",
    "dictionary = corpora.Dictionary([words])\n",
    "corpus = [dictionary.doc2bow(words)]\n",
    "lda = models.LdaModel(corpus, id2word=dictionary, num_topics=1)\n",
    "\n",
    "for topic_id, topic in lda.print_topics(num_words=5):\n",
    "    keywords = [word.rstrip('\"').split(r'*\"') for word in topic.split(\" + \")]\n",
    "\n",
    "weight = [float(word[0]) for word in keywords]\n",
    "keywords = [word[1] for word in keywords]\n",
    "\n",
    "for i in range(len(keywords)):\n",
    "    print(f\"{keywords[i]} {weight[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyword Extraction using jieba TextRank\n",
    "\n",
    "for x, w in jieba.analyse.textrank(s, withWeight=True)[:5]:\n",
    "    print('%s %s' % (x, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyword Extraction using TF-IDF by hand\n",
    "\n",
    "idf = {}\n",
    "with open(\"../source/idf.txt.big\", 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().splitlines()\n",
    "    for line in lines:\n",
    "        word, value = line.split()\n",
    "        idf[word] = float(value)\n",
    "\n",
    "def TF_IDF(words, idf):\n",
    "    tfidf = {}\n",
    "    tf = {}\n",
    "    for word in words:\n",
    "        if word in tf:\n",
    "            tf[word] += 1\n",
    "        else:\n",
    "            tf[word] = 1\n",
    "    for word in tf:\n",
    "        tf[word] = tf[word] / len(words)\n",
    "        tfidf[word] = tf[word] * idf.get(word, 14)\n",
    "    return tfidf\n",
    "\n",
    "tfidf = TF_IDF(words, idf)\n",
    "for word in sorted(tfidf.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print(word[0], word[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
